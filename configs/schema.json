{"GPU": {"type": "object", "properties": {"wantsMore": {"type": "boolean", "description": "Set to `true` to use all visible gpus and all VRams and ignore `gpus` and `vRam`."}, "vRam": {"type": "integer", "description": "Minimum VRam required for each gpu. Set it to `-1` to use all gpus."}, "gpus": {"type": "integer", "description": "Number of gpus for training. This affects the `world size` of PyTorch DDP.", "exclusiveMinimum": 0}}}, "General": {"type": "object", "properties": {"key": {"type": "string", "description": "A unique key used to retrieve in registry. For example, given `Lamb` for optimizers, it will check `OptimRegistry` and find the optimizer `apex.optim.FusedLAMB`."}, "params": {"type": ["string", "number", "boolean"], "description": "Corresponding funcation call parameters. So the whole call is `registry.get(key)(**params)`.", "additionalProperties": {}}}}, "Train": {"type": "object", "properties": {"valSet": {"type": "string", "description": "A dir path to load image files for validation."}, "target": {"type": "string", "description": "Training target. Now is one of `[PSNR, MsSSIM]`.", "enum": ["PSNR", "MsSSIM"]}, "valFreq": {"type": "integer", "description": "Run validation after every `valFreq` epochs.", "exclusiveMinimum": 0}, "gpu": {"description": "GPU configs for training.", "additionalProperties": false, "allOf": [{"$ref": "#/GPU"}]}, "trainSet": {"type": "string", "description": "A dir path to load `lmdb` dataset. You need to convert your images before you give this path by calling `mcquic dataset ...`."}, "saveDir": {"type": "string", "description": "A dir path to save model checkpoints, TensorBoard messages and logs."}, "batchSize": {"type": "integer", "description": "Batch size for training. NOTE: The actual batch size (whole world) is computed by `batchSize * gpus`.", "exclusiveMinimum": 0}, "epoch": {"type": "integer", "description": "Total training epochs.", "exclusiveMinimum": 0}, "optim": {"description": "Optimizer used for training. As for current we have `Adam` and `Lamb`.", "additionalProperties": false, "allOf": [{"$ref": "#/General"}]}, "schdr": {"description": "Learning rate scheduler used for training. As for current we have `ReduceLROnPlateau`, `Exponential`, `MultiStep`, `OneCycle` and all schedulers defined in `mcquic.train.lrSchedulers`.", "additionalProperties": false, "allOf": [{"$ref": "#/General"}]}}}, "type": "object", "properties": {"train": {"description": "Training configs.", "additionalProperties": false, "allOf": [{"$ref": "#/Train"}]}, "model": {"description": "Compression model to use. Now we only have one model, so `key` is ignored. Avaliable params are `channel`, `m` and `k`.", "additionalProperties": false, "allOf": [{"$ref": "#/General"}]}}, "title": "Config schema", "description": "The bravo schema for writing a config!"}